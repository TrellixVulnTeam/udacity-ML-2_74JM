{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得当前目录\n",
    "current_dir = os.getcwd()\n",
    "def export_feature(MODEL, image_size, batch_size, preprocess_input=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if preprocess_input:\n",
    "        x = Lambda(preprocess_input)(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "#     base_model.save_weights(base_model.name+'-imagenet.h5')\n",
    "    \n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    \n",
    "    train_generator = gen.flow_from_directory(current_dir + '/data/train', image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    test_generator = gen.flow_from_directory(current_dir + \"/data/test\", image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "\n",
    "    train_feature = model.predict_generator(train_generator, train_generator.samples, workers=8, verbose=1)\n",
    "    test_feature = model.predict_generator(test_generator, test_generator.samples, workers=8, verbose=1)\n",
    "    with h5py.File(\"feature_%s.h5\"%base_model.name) as h:\n",
    "        h.create_dataset(\"train\", data=train_feature)\n",
    "        h.create_dataset(\"test\", data=test_feature)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "25000/25000 [==============================] - 771s 31ms/step\n",
      "12500/12500 [==============================] - 351s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "export_feature(ResNet50, (224, 224), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "25000/25000 [==============================] - 1047s 42ms/step\n",
      "12500/12500 [==============================] - 522s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "export_feature(InceptionV3, (299, 299), batch_size=1, preprocess_input=inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "25000/25000 [==============================] - 937s 37ms/step\n",
      "12500/12500 [==============================] - 469s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "export_feature(Xception, (299, 299), batch_size=1, preprocess_input=xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "76398592/76391848 [==============================] - 1s 0us/step - ETA: \n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "25000/25000 [==============================] - 1995s 80ms/step\n",
      "12500/12500 [==============================] - 986s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "export_feature(DenseNet201, (224, 224), batch_size=1, preprocess_input=densenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_feature(DenseNet169, (224, 224), batch_size=1, preprocess_input=densenet.preprocess_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
