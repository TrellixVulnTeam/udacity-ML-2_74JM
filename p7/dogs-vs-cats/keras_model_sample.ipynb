{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=784))\n",
    "model2.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多分类问题\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# 二分类问题\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# 均方误差回归问题\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='mse')\n",
    "\n",
    "# 自定义评估标准函数\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 267us/step - loss: 0.7026 - acc: 0.4920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6920 - acc: 0.5390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6885 - acc: 0.5400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6837 - acc: 0.5770\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6798 - acc: 0.5650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6766 - acc: 0.5700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6710 - acc: 0.5830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6689 - acc: 0.5950\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6640 - acc: 0.5930\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6622 - acc: 0.6130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18217d15f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于具有2个类的单输入模型（二进制分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 175us/step - loss: 2.3355 - acc: 0.1200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 2.3049 - acc: 0.1320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 2.2891 - acc: 0.1340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.2835 - acc: 0.1360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 2.2772 - acc: 0.1340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.2719 - acc: 0.1360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.2645 - acc: 0.1530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 2.2588 - acc: 0.1520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 2.2534 - acc: 0.1610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 2.2459 - acc: 0.1590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1821d9f5c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于具有10个类的单输入模型（多分类分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# 将标签转换为分类的 one-hot 编码\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知器 (MLP) 的 softmax 多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda2/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 203us/step - loss: 2.3949 - acc: 0.1090\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3546 - acc: 0.1110\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3331 - acc: 0.0970\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3244 - acc: 0.1180\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3189 - acc: 0.1130\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3122 - acc: 0.1100\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3059 - acc: 0.1090\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3096 - acc: 0.1100\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 2.3087 - acc: 0.1130\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3047 - acc: 0.1150\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3019 - acc: 0.1160\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3116 - acc: 0.1080\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3100 - acc: 0.1170\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.3036 - acc: 0.1130\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.3078 - acc: 0.1110\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.3093 - acc: 0.1070\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.2990 - acc: 0.1090\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3046 - acc: 0.1050\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.2960 - acc: 0.1060\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 2.2974 - acc: 0.1230\n",
      "100/100 [==============================] - 0s 393us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) 是一个具有 64 个隐藏神经元的全连接层。\n",
    "# 在第一层必须指定所期望的输入数据尺寸：\n",
    "# 在这里，是一个 20 维的向量。\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3046202659606934, 0.11999999731779099]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知器的二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 230us/step - loss: 0.7064 - acc: 0.5200\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.7020 - acc: 0.5190\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.7090 - acc: 0.4880\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6985 - acc: 0.5110\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6942 - acc: 0.5400\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6924 - acc: 0.5420\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 0.6985 - acc: 0.5210\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6934 - acc: 0.5290\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6933 - acc: 0.5280\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6906 - acc: 0.5250\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6963 - acc: 0.5060\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 0.6903 - acc: 0.5270\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6917 - acc: 0.5300\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6901 - acc: 0.5290\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6900 - acc: 0.5510\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6900 - acc: 0.5510\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6853 - acc: 0.5490\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6925 - acc: 0.5140\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6884 - acc: 0.5350\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6871 - acc: 0.5250\n",
      "100/100 [==============================] - 0s 632us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6874599456787109, 0.5400000214576721]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类似 VGG 的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 2.3070\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.3744\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.3011\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.2868\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.2640\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.2778\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.2614\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.2919\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.2798\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 2.2709\n",
      "20/20 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# 输入: 3 通道 100x100 像素图像 -> (100, 100, 3) 张量。\n",
    "# 使用 32 个大小为 3x3 的卷积滤波器。\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.316540241241455\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 LSTM 的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f1525d2d3db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_features' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 1D 卷积的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8ea91fd81652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_length' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于栈式 LSTM 的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 11.5740 - acc: 0.1090 - val_loss: 11.5335 - val_acc: 0.1600\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 343us/step - loss: 11.5714 - acc: 0.1060 - val_loss: 11.5358 - val_acc: 0.0800\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 344us/step - loss: 11.5717 - acc: 0.1050 - val_loss: 11.5337 - val_acc: 0.1300\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 323us/step - loss: 11.5704 - acc: 0.1090 - val_loss: 11.5356 - val_acc: 0.0800\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 335us/step - loss: 11.5705 - acc: 0.1060 - val_loss: 11.5354 - val_acc: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1825041898>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(32, return_sequences=True))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(32))  # 返回维度为 32 的单个向量\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 带有状态 (stateful) 的 相同的栈式 LSTM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 96 samples\n",
      "Epoch 1/5\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 11.7200 - acc: 0.1062 - val_loss: 11.3631 - val_acc: 0.1667\n",
      "Epoch 2/5\n",
      "320/320 [==============================] - 0s 506us/step - loss: 11.7158 - acc: 0.1062 - val_loss: 11.3615 - val_acc: 0.1458\n",
      "Epoch 3/5\n",
      "320/320 [==============================] - 0s 506us/step - loss: 11.7151 - acc: 0.1062 - val_loss: 11.3612 - val_acc: 0.1562\n",
      "Epoch 4/5\n",
      "320/320 [==============================] - 0s 510us/step - loss: 11.7144 - acc: 0.1062 - val_loss: 11.3611 - val_acc: 0.1667\n",
      "Epoch 5/5\n",
      "320/320 [==============================] - 0s 512us/step - loss: 11.7139 - acc: 0.1125 - val_loss: 11.3611 - val_acc: 0.1458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182d04c5c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "# 请注意，我们必须提供完整的 batch_input_shape，因为网络是有状态的。\n",
    "# 第 k 批数据的第 i 个样本是第 k-1 批数据的第 i 个样本的后续。\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=5, shuffle=False,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输入多输出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# 标题输入：接收一个含有 100 个整数的序列，每个整数在 1 到 10000 之间。\n",
    "# 注意我们可以通过传递一个 `name` 参数来命名任何层。\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# Embedding 层将输入序列编码为一个稠密向量的序列，每个向量维度为 512。\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# LSTM 层把向量序列转换成单个向量，它包含整个序列的上下文信息\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# 堆叠多个全连接网络层\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# 最后添加主要的逻辑回归层\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headline_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7514b3e18c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit([headline_data, additional_data], [labels, labels],\n\u001b[0m\u001b[1;32m      2\u001b[0m           epochs=50, batch_size=32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'headline_data' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit([headline_data, additional_data], [labels, labels],\n",
    "          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headline_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7b263c608dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 然后使用以下方式训练：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model.fit({'main_input': headline_data, 'aux_input': additional_data},\n\u001b[0m\u001b[1;32m      7\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m'main_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aux_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           epochs=50, batch_size=32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'headline_data' is not defined"
     ]
    }
   ],
   "source": [
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "#               loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# # 然后使用以下方式训练：\n",
    "# model.fit({'main_input': headline_data, 'aux_input': additional_data},\n",
    "#           {'main_output': labels, 'aux_output': labels},\n",
    "#           epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层上的残差连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "# 输入张量为 3 通道 256x256 图像\n",
    "x = Input(shape=(256, 256, 3))\n",
    "# 3 输出通道（与输入通道相同）的 3x3 卷积核\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "# 返回 x + y\n",
    "z = keras.layers.add([x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享视觉模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# 首先，定义视觉模型\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "# 然后，定义区分数字的模型\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "# 视觉模型将被共享，包括权重和其他所有\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 视觉问答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# 首先，让我们用 Sequential 来定义一个视觉模型。\n",
    "# 这个模型会把一张图像编码为向量。\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "# 现在让我们用视觉模型来得到一个输出张量：\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "# 接下来，定义一个语言模型来将问题编码成一个向量。\n",
    "# 每个问题最长 100 个词，词的索引从 1 到 9999.\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "# 连接问题向量和图像向量：\n",
    "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
    "\n",
    "# 然后在上面训练一个 1000 词的逻辑回归模型：\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "# 最终模型：\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "\n",
    "# 下一步就是在真实数据上训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 视频问答模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "video_input = Input(shape=(100, 224, 224, 3))\n",
    "# 这是基于之前定义的视觉模型（权重被重用）构建的视频编码\n",
    "encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # 输出为向量的序列\n",
    "encoded_video = LSTM(256)(encoded_frame_sequence)  # 输出为一个向量\n",
    "\n",
    "# 这是问题编码器的模型级表示，重复使用与之前相同的权重：\n",
    "question_encoder = Model(inputs=question_input, outputs=encoded_question)\n",
    "\n",
    "# 让我们用它来编码这个问题：\n",
    "video_question_input = Input(shape=(100,), dtype='int32')\n",
    "encoded_video_question = question_encoder(video_question_input)\n",
    "\n",
    "# 这就是我们的视频问答模式：\n",
    "merged = keras.layers.concatenate([encoded_video, encoded_video_question])\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
